<!DOCTYPE html>
<!-- saved from url=(0044)http://herohuyongtao.github.io/publications/ -->
<html class="js no-flexbox canvas canvastext webgl no-touch geolocation postmessage websqldatabase indexeddb hashchange history draganddrop websockets rgba hsla multiplebgs backgroundsize borderimage borderradius boxshadow textshadow opacity cssanimations csscolumns cssgradients cssreflections csstransforms csstransforms3d csstransitions fontface generatedcontent video audio localstorage sessionstorage webworkers applicationcache svg inlinesvg smil svgclippaths gr_chenweikai_github_io" lang="en"><!--<![endif]--><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	

	<title>Zhiyang (Frank) Dou | Research</title>

	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<script src="./publications/modernizr-2.5.3.min.js.download"></script>

	<script src="./publications/jquery.min.js.download"></script>
	<script>window.jQuery || document.write('<script src="/js/vendor/jquery-1.7.2.min.js"><\/script>')</script>

	<script src="./publications/spamspan.min.js.download"></script>
	<script src="./publications/prettify.js.download"></script>

	<link rel="stylesheet" href="./files/social_widget.css">
	<link rel="stylesheet" href="./files/glyphicons.css">
	<link rel="stylesheet" href="./files/bootstrap.css">
	<link rel="stylesheet" href="./files/bootstrap-responsive.css">
	<link rel="stylesheet" href="./files/app.css">
	<!-- <link rel="stylesheet" href="./files/font-awesome.min.css"> -->
	<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
	<script type="text/javascript" src="./files/plugins.js.download"></script>
	<script type="text/javascript" src="./files/main.js.download"></script>
	<link rel="canonical" href="http://chenweikai.github.io/">

	<!-- to toggle text -->
	<style type="text/css">
		a.toggle_text_link {
			cursor:pointer;
		}

		pre.invisible_text {
			display: none;
		}
	</style>
	<script language="javascript" type="text/javascript">
		function toggle(element) {
			if(element.style.display=="block") {
				element.style.display="none";
			} else {
				element.style.display="block";
			}
		}
	</script>
</head>

<body class="page page-id-25 page-parent page-template-default top-navbar" data-gr-c-s-loaded="true">
  <!--[if lt IE 7]><div class="alert">Your browser is <em>ancient!</em> <a href="http://browsehappy.com/">Upgrade to a different browser</a> or <a href="http://www.google.com/chromeframe/?redirect=true">install Google Chrome Frame</a> to experience this site.</div><![endif]-->

    <header id="banner" class="navbar navbar-fixed-top" role="banner">
		<div class="navbar-inner">
			<div class="container">
				<a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
					<span class="icon-bar"></span>
					<span class="icon-bar"></span>
					<span class="icon-bar"></span>
				</a>
				<a class="brand" href="http://Frank-ZY-Dou.github.io/">
					Zhiyang (Frank) Dou
				</a>
				<nav id="nav-main" class="nav-collapse" role="navigation">
					<ul class="nav">
						<li class="menu-home"><a href="http://Frank-ZY-Dou.github.io/">Home</a></li>
						<li class="menu-publications active active"><a href="http://Frank-ZY-Dou.github.io/publication.html">Publications</a></li>
					</ul>
				</nav>
			</div>
		</div>
	</header>

    <div id="wrap" class="container" role="document">
		<div id="content" class="row">
			<!-- publications div -->
			<div id="main" class="span12" role="main">
				<div class="page-header">
					<h1>Publications</h1>

				</div>
			</div>	
				
					
				</div>
				<!-- 2019 publications 
				<div class="row" style="margin-bottom: 1em;">
					<div class="span6 offset3">
						<h2>2019</h2>
					</div>
				</div>
				-->


				<div class="row" style="margin-bottom: 1em;">
					<div class="span2 offset2">
					     <p align="left">* Equal contribution.</p>
					</div>
				</div>

		<div class="row" style="margin-bottom: 1em;">
					<div class="span2 offset2">
						<a href="http://Frank-ZY-Dou.github.io/publication.html">
							<img class="dropshadow pull-right" alt="" src="./figures/23_wonder3D_.png" width="200" height="120">
						</a>
					</div>
					<div class="span6">
							<a href="">
								<strong>Wonder3D: Single Image to 3D using Cross-Domain Diffusion</strong>
							</a>
							<br>Xiaoxiao Long*, Yuanchen Guo*, Cheng Lin, Yuan Liu, <strong>Zhiyang Dou</strong>, Lingjie Liu, Yuexin Ma, Song-Hai Zhang, Marc Habermann, Christian Theobalt, Wenping Wang.<br>
							<em> <b>Arxiv 2023.</b></em>
							<br>

							<br>
							<ul class="inline middot">
								<li><em class="fa fa-file"></em> <a href="https://www.xxlong.site/Wonder3D/">project page</a></li>
								<li><em class="fa fa-file"></em> <a href="https://arxiv.org/abs/2310.15008">paper</a></li>
<!--								<li><em class="fa fa-file"></em> <a href="https://youtu.be/Cgq6JbQ1VW4">video</a></li>-->
								<li><em class="fa fa-file"></em> <a href="https://github.com/xxlong0/Wonder3D">code</a></li>
								<!-- <li><em class="fa fa-file"></em> <a href="https://diglib.eg.org/bitstream/handle/10.1111/cgf14484/paper1026_1.pdf?sequence=2&isAllowed=y">suppl.</a></li> -->
								<!--<li><em class="fa fa-file"></em> <a href="https://www.youtube.com/watch?v=xjTVECIqZfc&feature=youtu.be">video</a></li> -->
								<li>
									<em class="fa fa-bars"></em>
									<a class="toggle_text_link" onclick="javascript:toggle(wonder3d);">abstract</a>
									<pre id="wonder3d" class="invisible_text">In this work, we introduce Wonder3D, a novel method for efficiently generating high-fidelity textured meshes from single-view images.Recent methods based on Score Distillation Sampling (SDS) have shown the potential to recover 3D geometry from 2D diffusion priors, but they typically suffer from time-consuming per-shape optimization and inconsistent geometry. In contrast, certain works directly produce 3D information via fast network inferences, but their results are often of low quality and lack geometric details. To holistically improve the quality, consistency, and efficiency of image-to-3D tasks, we propose a cross-domain diffusion model that generates multi-view normal maps and the corresponding color images. To ensure consistency, we employ a multi-view cross-domain attention mechanism that facilitates information exchange across views and modalities. Lastly, we introduce a geometry-aware normal fusion algorithm that extracts high-quality surfaces from the multi-view 2D representations. Our extensive evaluations demonstrate that our method achieves high-quality reconstruction results, robust generalization, and reasonably good efficiency compared to prior works.</pre> <!-- put </pre> on this line to avoid new unwanted line breaks after bibtex -->
								</li>
							</ul>

						</div>
				</div>
		<br>


		<div class="row" style="margin-bottom: 1em;">
					<div class="span2 offset2">
						<a href="http://Frank-ZY-Dou.github.io/publication.html">
							<img class="dropshadow pull-right" alt="" src="./figures/23_SIGA_EASE.png" width="200" height="120">
						</a>
					</div>
					<div class="span6">
							<a href="">
							<strong>C·ASE: Learning Conditional Adversarial Skill Embeddings for Physics-based Characters</strong>
						</a>
						<br><strong>Zhiyang Dou</strong>, Xuelin Chen, Qingnan Fan, Taku Komura, Wenping Wang.<br>
						<em> <b>SIGGRAPH Asia 2023.</b></em>
						<br>
						&nbsp;
						<br>
						<ul class="inline middot">
							<li><em class="fa fa-file"></em> <a href="https://frank-zy-dou.github.io/projects/CASE/index.html">project page</a></li>
							<li><em class="fa fa-file"></em> <a href="https://arxiv.org/abs/2309.11351">paper</a></li>
							<li><em class="fa fa-file"></em> <a href="https://youtu.be/Cgq6JbQ1VW4">video</a></li>
							<li><em class="fa fa-file"></em> <a href="">code (coming soon)</a></li>
							<!-- <li><em class="fa fa-file"></em> <a href="https://diglib.eg.org/bitstream/handle/10.1111/cgf14484/paper1026_1.pdf?sequence=2&isAllowed=y">suppl.</a></li> -->
							<!--<li><em class="fa fa-file"></em> <a href="https://www.youtube.com/watch?v=xjTVECIqZfc&feature=youtu.be">video</a></li> -->
							<li>
								<em class="fa fa-bars"></em>
								<a class="toggle_text_link" onclick="javascript:toggle(ease);">abstract</a>
								<pre id="ease" class="invisible_text">We present C·ASE, an efficient and effective framework that learns Conditional Adversarial Skill Embeddings for physics-based characters. C·ASE enables the physically simulated character to learn a diverse repertoire of skills while providing controllability in the form of direct manipulation of the skills to be performed. This is achieved by dividing the heterogeneous skill motions into distinct subsets containing homogeneous samples for training a low-level conditional model to learn the conditional behavior distribution. The skill-conditioned imitation learning naturally offers explicit control over the character’s skills after training. The training course incorporates the focal skill sampling, skeletal residual forces, and element-wise feature masking to balance diverse skills of varying complexities, mitigate dynamics mismatch to master agile motions and capture more general behavior characteristics, respectively. Once trained, the conditional model can produce highly diverse and realistic skills, outperforming state-of-the-art models, and can be repurposed in various downstream tasks. In particular, the explicit skill control handle allows a high-level policy or a user to direct the character with desired skill specifications, which we demonstrate is advantageous for interactive character animation.</pre> <!-- put </pre> on this line to avoid new unwanted line breaks after bibtex -->
								</pre> <!-- put </pre> on this line to avoid new unwanted line breaks after bibtex -->
							</li>
						</ul>
					</div>
				</div>
		<br>
		<div class="row" style="margin-bottom: 1em;">
					<div class="span2 offset2">
						<a href="http://Frank-ZY-Dou.github.io/publication.html">
							<img class="dropshadow pull-right" alt="" src="./figures/23_ICCV_TORE.png" width="200" height="120">
						</a>
					</div>
					<div class="span6">
						<a href="">
							<strong>TORE: Token Reduction for Efficient Human Mesh Recovery with Transformer</strong>
						</a>
						<br><strong>Zhiyang Dou</strong>*, Qingxuan Wu*, Cheng Lin, Zeyu Cao, Qiangqiang Wu, Weilin Wan, Taku Komura, Wenping Wang.<br>
						<em> <b> IEEE International Conference on Computer Vision (ICCV) 2023.</b></em>
						<br>
						<!-- <em>"a learnable implicit representation for modeling both closed and open surfaces"</em> -->
						<br>
						<ul class="inline middot">
							<li><em class="fa fa-file"></em> <a href="https://frank-zy-dou.github.io/projects/Tore/index.html">project page</a></li>
							<li><em class="fa fa-file"></em> <a href="https://arxiv.org/abs/2211.10705">paper</a></li>
							<li><em class="fa fa-file"></em> <a href="https://github.com/Frank-ZY-Dou/TORE">code</a></li>
							<!-- <li><em class="fa fa-file"></em> <a href="https://diglib.eg.org/bitstream/handle/10.1111/cgf14484/paper1026_1.pdf?sequence=2&isAllowed=y">suppl.</a></li> -->
							<!--<li><em class="fa fa-file"></em> <a href="https://www.youtube.com/watch?v=xjTVECIqZfc&feature=youtu.be">video</a></li> -->
							<li>
								<em class="fa fa-bars"></em>
								<a class="toggle_text_link" onclick="javascript:toggle(tore);">abstract</a>
								<pre id="tore" class="invisible_text">In this paper, we introduce a set of effective TOken REduction (TORE) strategies for Transformer-based Human Mesh Recovery from monocular images. Current SOTA performance is achieved by Transformer-based structures. However, they suffer from high model complexity and computation cost caused by redundant tokens. We propose token reduction strategies based on two important aspects, i.e., the 3D geometry structure and 2D image feature, where we hierarchically recover the mesh geometry with priors from body structure and conduct token clustering to pass fewer but more discriminative image feature tokens to the Transformer. As a result, our method vastly reduces the number of tokens involved in high-complexity interactions in the Transformer, achieving competitive accuracy of shape recovery at a significantly reduced computational cost. We conduct extensive experiments across a wide range of benchmarks to validate the proposed method and further demonstrate the generalizability of our method on hand mesh recovery. Our code will be publicly available once the paper is published.
</pre> <!-- put </pre> on this line to avoid new unwanted line breaks after bibtex -->
							</li>
						</ul>
					</div>
				</div>
		<br>
				<div class="row" style="margin-bottom: 1em;">
					<div class="span2 offset2">
						<a href="http://Frank-ZY-Dou.github.io/publication.html">
							<img class="dropshadow pull-right" alt="" src="./figures/23_SIG_GCNO.png" width="200" height="120">
						</a>
					</div>
					<div class="span6" style="margin-bottom: 0em;">
						<a href="">
							<strong>Globally Consistent Normal Orientation for Point Clouds by Regularizing the Winding-Number Field</strong>
						</a>
						<br>Rui Xu, <strong>Zhiyang Dou</strong>, Ningna Wang,  Shiqing Xin, Shuangmin Chen, Mingyan Jiang, Xiaohu Guo, Wenping Wang, Changhe Tu.<br>
						<em> <b>ACM Transactions on Graphics. SIGGRAPH 2023.</b></em>
						<p style="color: rgb(205,97,85)"><strong>SIGGRAPH 2023 Best Paper Award; See more <a href="https://blog.siggraph.org/2023/07/siggraph-2023-technical-papers-awards-best-papers-honorable-mentions-and-test-of-time.html/">here</a>.</strong></p>
						<ul class="inline middot">
							<li><em class="fa fa-file"></em> <a href="https://xrvitd.github.io/Projects/GCNO/index.html">project page</a></li>
							<li><em class="fa fa-file"></em> <a href="https://arxiv.org/abs/2304.11605">paper</a></li>
							<li><em class="fa fa-file"></em> <a href="https://www.youtube.com/watch?v=08pOt5JqWJE&ab_channel=N">video</a></li>
							<li><em class="fa fa-file"></em> <a href="https://github.com/Xrvitd/GCNO">code</a></li>
							<li>
								<em class="fa fa-bars"></em>
								<a class="toggle_text_link" onclick="javascript:toggle(GCNO);">abstract</a>
								<pre id="GCNO" class="invisible_text">Estimating normals with globally consistent orientations for a raw point cloud has many downstream geometry processing applications. Despite tremendous efforts in the past decades, it remains challenging to deal with an unoriented point cloud with various imperfections, particularly in the presence of data sparsity coupled with nearby gaps or thin-walled structures. In this paper, we propose a smooth objective function to characterize the requirements of an acceptable winding-number field, which allows one to find the globally consistent normal orientations starting from a set of completely random normals. By taking the vertices of the Voronoi diagram of the point cloud as examination points, we consider the following three requirements: (1) the winding number is either 0 or 1, (2) the occurrences of 1 and the occurrences of 0 are balanced around the point cloud, and (3) the normals align with the outside Voronoi poles as much as possible. Extensive experimental results show that our method outperforms the existing approaches, especially in handling sparse and noisy point clouds, as well as shapes with complex geometry/topology.</pre>
							</li>
						</ul>
					</div>
				</div>
<!--		<br>-->
				<div class="row" style="margin-bottom: 1em;">
					<div class="span2 offset2">
						<a href="http://Frank-ZY-Dou.github.io/publication.html">
							<img class="dropshadow pull-right" alt="" src="./figures/22_SIGA_rfeps.png" width="200" height="120">
						</a>
					</div>
					<div class="span6">
						<a href="">
							<strong>RFEPS: Reconstructing Feature-line Equipped Polygonal Surface</strong>
						</a>
						<br>Rui Xu, Zixiong Wang, <strong>Zhiyang Dou</strong>, Chen Zong, Shiqing Xin, Mingyan Jiang, Tao Ju, Changhe Tu.<br>
						<em> <b>ACM Transactions on Graphics. SIGGRAPH Asia 2022.</b></em>
<!--						<br>-->
						<!-- <em>"a learnable implicit representation for modeling both closed and open surfaces"</em> -->
						<br>
						<ul class="inline middot">
							<li><em class="fa fa-file"></em> <a href="https://xrvitd.github.io/Projects/RFEPS/index.html">project page</a></li>
							<li><em class="fa fa-file"></em> <a href="https://arxiv.org/abs/2212.03600">paper</a></li>
							<li><em class="fa fa-file"></em> <a href="https://www.youtube.com/watch?v=iRP5z-JOCEc&ab_channel=%E5%BE%90%E7%91%9E">video</a></li>
							<li><em class="fa fa-file"></em> <a href="https://github.com/Xrvitd/RFEPS">code</a></li>
							<!-- <li><em class="fa fa-file"></em> <a href="./papers/[ECCV18]body supplementary.pdf">suppl.</a></li> -->
							<!--<li><em class="fa fa-file"></em> <a href="https://www.youtube.com/watch?v=xjTVECIqZfc&feature=youtu.be">video</a></li> -->
							<li>
								<em class="fa fa-bars"></em>
								<a class="toggle_text_link" onclick="javascript:toggle(rfeps);">abstract</a>
								<pre id="rfeps" class="invisible_text">Feature lines are important geometric cues in characterizing the structure of a CAD model. Despite great progress in both explicit reconstruction and implicit reconstruction, it remains a challenging task to reconstruct a polygonal surface equipped with feature lines, especially when the input point cloud is noisy and lacks faithful normal vectors. In this paper, we develop a multistage algorithm, named RFEPS, to address this challenge. The key steps include (1)denoising the point cloud based on the assumption of local planarity, (2)identifying the feature-line zone by optimization of discrete optimal transport, (3)augmenting the point set so that sufficiently many additional points are generated on potential geometry edges, and (4) generating a polygonal surface that interpolates the augmented point set based on restricted power diagram. We demonstrate through extensive experiments that RFEPS, benefiting from the edge-point augmentation and the feature-preserving explicit reconstruction, outperforms state-of-the-art methods in terms of the reconstruction quality, especially in terms of the ability to reconstruct missing feature lines.</pre> <!-- put </pre> on this line to avoid new unwanted line breaks after bibtex -->
							</li>
							
						</ul>
					</div>
				</div>
		<br>
				<div class="row" style="margin-bottom: 1em;">
					<div class="span2 offset2">
						<a href="http://Frank-ZY-Dou.github.io/publication.html">
							<img class="dropshadow pull-right" alt="" src="./figures/22_EG_CAT.png" width="200" height="120">
						</a>
					</div>
					<div class="span6">
						<a href="">
							<strong>Coverage Axis: Inner Point Selection for 3D Shape Skeletonization</strong>
						</a>
						<br><strong>Zhiyang Dou</strong>, Cheng Lin, Rui Xu, Lei Yang, Shiqing Xin, Taku Komura, Wenping Wang.<br>
						<em> <b>Computer Graphics Forum. Eurographics 2022.</b></em>
<!--						<br>-->
												<p style="color: rgb(205,97,85)"><strong>Fast-Forward Attendees Award, 2nd Place.</strong></p>
						<ul class="inline middot">
							<li><em class="fa fa-file"></em> <a href="https://frank-zy-dou.github.io/projects/CoverageAxis/index.html">project page</a></li>
							<li><em class="fa fa-file"></em> <a href="https://arxiv.org/abs/2110.00965">paper</a></li>
							<li><em class="fa fa-file"></em> <a href="https://github.com/Frank-ZY-Dou/Coverage_Axis">code</a></li>
							<li><em class="fa fa-file"></em> <a href="https://diglib.eg.org/bitstream/handle/10.1111/cgf14484/paper1026_1.pdf?sequence=2&isAllowed=y">suppl.</a></li>
							<!--<li><em class="fa fa-file"></em> <a href="https://www.youtube.com/watch?v=xjTVECIqZfc&feature=youtu.be">video</a></li> -->
							<li>
								<em class="fa fa-bars"></em>
								<a class="toggle_text_link" onclick="javascript:toggle(cat);">abstract</a>
								<pre id="cat" class="invisible_text">In this paper, we present a simple yet effective formulation called Coverage Axis for 3D shape skeletonization. Inspired by the set cover problem, our key idea is to cover all the surface points using as few inside medial balls as possible. This formulation inherently induces a compact and expressive approximation of the Medial Axis Transform (MAT) of a given shape. Different from previous methods that rely on local approximation error, our method allows a global consideration of the overall shape structure, leading to an efficient high-level abstraction and superior robustness to noise. Another appealing aspect of our method is its capability to handle more generalized input such as point clouds and poor-quality meshes. Extensive comparisons and evaluations demonstrate the remarkable effectiveness of our method for generating compact and expressive skeletal representation to approximate the MAT.</pre> <!-- put </pre> on this line to avoid new unwanted line breaks after bibtex -->
							</li>
						</ul>
					</div>
				</div>
		<br>

		<div class="row" style="margin-bottom: 1em;">
					<div class="span2 offset2">
						<a href="http://Frank-ZY-Dou.github.io/publication.html">
							<img class="dropshadow pull-right" alt="" src="./figures/23_SCS_HST.png" width="200" height="120">
						</a>
					</div>
					<div class="span6">
						<a href="">
							<strong>Popularization of High-Speed Railway Reduces the Infection Risk via Close Contact Route during Journey</strong>
						</a>
						<br>Nan Zhang, Xiyue Liu, Shuyi Gao, Boni Su, <strong>Zhiyang Dou</strong>#.<br>
						<em> <b>Sustainable Cities and Society (SCS) 2023, IF=11.7.</b></em>
						<br>
						# Corresponding Author.
						<br>
						<ul class="inline middot">
							<li><em class="fa fa-file"></em> <a href="">paper</a></li>
							<!--<li><em class="fa fa-file"></em> <a href="https://www.youtube.com/watch?v=xjTVECIqZfc&feature=youtu.be">video</a></li> -->
							<li>
								<em class="fa fa-bars"></em>
								<a class="toggle_text_link" onclick="javascript:toggle(scs23_HST);">abstract</a>
								<pre id="scs23_HST" class="invisible_text">The risk of COVID-19 infection has increased due to the prolonged duration of travel and frequent close interactions due to popularization of railway transportations. This study utilized depth detection devices to analyze the close contact behaviors of passengers in high-speed train (HST), traditional trains (TT), waiting area in waiting room (WWR), and ticket check area in waiting room (CWR). A multi-route COVID-19 transmission model was developed to assess the risk of virus exposure in these scenarios under various non-pharmaceutical interventions. A total of 163,740 seconds of data was collected. The close contact ratios in HST, TT, WWR, and CWR was 5.8%, 64.0%, 7.7%, and 49.0%, respectively. The average interpersonal distance between passengers was 0.85 m, 0.92 m, 1.25 m, and 0.88 m, respectively. The probability of face-to-face contact was 9.5%, 70.0%, 64.2%, and 5.8% across each environment, respectively. When all passengers wore N95 respirators and surgical masks, the personal virus exposure via close contact can be reduced by 94.1% and 51.9%, respectively. The virus exposure in TT is about dozens of times of it in HST. In China, if all current railway traffic was replaced by HST, the total virus exposure of passengers can be reduced by roughly 50%. </pre>
							</li>
						</ul>
					</div>
				</div>
		<br>

		<div class="row" style="margin-bottom: 1em;">
					<div class="span2 offset2">
						<a href="http://Frank-ZY-Dou.github.io/publication.html">
							<img class="dropshadow pull-right" alt="" src="./figures/23_STE_.png" width="200" height="120">
						</a>
					</div>
					<div class="span6">
						<a href="">
							<strong>Analysis of SARS-CoV-2 Transmission in a University Classroom based on Real Human Close Contact Behaviors</strong>
						</a>
						<br>Nan Zhang, Xueze Yang, Boni Su, <strong>Zhiyang Dou</strong>#.<br>
						<em> <b>Under Review, 2023.</b></em>
						<br>
						# Corresponding Author.
						<br>
						<ul class="inline middot">
							<li><em class="fa fa-file"></em> <a href="">paper</a></li>
							<!--<li><em class="fa fa-file"></em> <a href="https://www.youtube.com/watch?v=xjTVECIqZfc&feature=youtu.be">video</a></li> -->
							<li>
								<em class="fa fa-bars"></em>
								<a class="toggle_text_link" onclick="javascript:toggle(scs23_ur);">abstract</a>
								<pre id="scs23_ur" class="invisible_text"> Under Review. </pre>
							</li>
						</ul>
					</div>
				</div>
		<br>




<!--		<div class="row">-->
<!--					<div class="span2" style="margin-bottom: 0em;">-->
<!--						<a href="https://frank-zy-dou.github.io/publication.html">-->
<!--							<img class="dropshadow pull-right" alt="" src="./figures/23_SCS_HST.png" width="200" height="120">-->
<!--						</a>-->
<!--					</div>-->
<!--					<div class="span6">-->
<!--						<a href="">-->
<!--							<strong>Popularization of High-Speed Railway Reduces the Infection Risk via Close Contact Route during Journey</strong>-->
<!--						</a>-->
<!--						<br>Nan Zhang, Xiyue Liu, Shuyi Gao, Boni Su, <strong>Zhiyang Dou</strong>#.<br>-->
<!--						<em> <b>Sustainable Cities and Society (SCS) 2023, IF=11.7</b></em>-->
<!--						<br>-->
<!--						# Corresponding Author.-->
<!--						<br>-->
<!--&lt;!&ndash;						<em>System development for close contact behavior collection.</em>&ndash;&gt;-->
<!--&lt;!&ndash;						<p style="color: rgb(205,97,85)"><strong>This research has been featured in a <a href="https://www.eurekalert.org/news-releases/989780">press release</a> by <a href="https://archive.eurekalert.org/aboutus.php" >EurekAlert!</a>.</strong></p>&ndash;&gt;-->
<!--&lt;!&ndash;							<br>-->

<!--&ndash;&gt;-->
<!--						<ul class="inline middot">-->
<!--&lt;!&ndash;							<li><em class="fa fa-file"></em> <a href="https://frank-zy-dou.github.io/projects/Pnas_nexus23/index.html">project page</a></li>&ndash;&gt;-->
<!--							<li><em class="fa fa-file"></em> <a href="">paper</a></li>-->
<!--&lt;!&ndash;							<li><em class="fa fa-file"></em> <a href="">press release</a></li>&ndash;&gt;-->
<!--							&lt;!&ndash; <li><em class="fa fa-file"></em> <a href="https://github.com/Xrvitd/RFEPS">code</a></li> &ndash;&gt;-->
<!--							&lt;!&ndash;<li><em class="fa fa-file"></em> <a href="https://www.youtube.com/watch?v=xjTVECIqZfc&feature=youtu.be">video</a></li> &ndash;&gt;-->
<!--							<li>-->
<!--								<em class="fa fa-bars"></em>-->
<!--								<a class="toggle_text_link" onclick="javascript:toggle(scs23_HST);">abstract</a>-->
<!--								<pre id="scs23_HST" class="invisible_text">The risk of COVID-19 infection has increased due to the prolonged duration of travel and frequent close interactions due to popularization of railway transportations. This study utilized depth detection devices to analyze the close contact behaviors of passengers in high-speed train (HST), traditional trains (TT), waiting area in waiting room (WWR), and ticket check area in waiting room (CWR). A multi-route COVID-19 transmission model was developed to assess the risk of virus exposure in these scenarios under various non-pharmaceutical interventions. A total of 163,740 seconds of data was collected. The close contact ratios in HST, TT, WWR, and CWR was 5.8%, 64.0%, 7.7%, and 49.0%, respectively. The average interpersonal distance between passengers was 0.85 m, 0.92 m, 1.25 m, and 0.88 m, respectively. The probability of face-to-face contact was 9.5%, 70.0%, 64.2%, and 5.8% across each environment, respectively. When all passengers wore N95 respirators and surgical masks, the personal virus exposure via close contact can be reduced by 94.1% and 51.9%, respectively. The virus exposure in TT is about dozens of times of it in HST. In China, if all current railway traffic was replaced by HST, the total virus exposure of passengers can be reduced by roughly 50%. </pre>-->
<!--							</li>-->
<!--						</ul>-->
<!--					</div>-->
<!--				</div>-->
<!--					<br>-->


				<div class="row" style="margin-bottom: 1em;">
					<div class="span2 offset2">
						<a href="https://frank-zy-dou.github.io/publication.html">
							<img class="dropshadow pull-right" alt="" src="./figures/23_PNAS_Nexus_student.png" width="200" height="120">
						</a>
					</div>
					<div class="span6">
						<a href="">
							<strong>Student close contact behavior and COVID-19 transmission in China’s classrooms</strong>
						</a>
						<br>Yong Guo*, <strong>Zhiyang Dou</strong>*, Nan Zhang, Xiyue Liu, Boni Su, Yuguo Li, Yinping Zhang.<br>
						<em> <b>PNAS Nexus 2023.</b></em>
<!--						<br>-->
<!--						<em>System development for close contact behavior collection.</em>-->
<!--						<br>-->
						<p style="color: rgb(205,97,85)"><strong>This research has been featured in a <a href="https://www.eurekalert.org/news-releases/989780">press release</a> by <a href="https://archive.eurekalert.org/aboutus.php" >EurekAlert!</a>.</strong></p>

						<ul class="inline middot">
							<li><em class="fa fa-file"></em> <a href="https://frank-zy-dou.github.io/projects/Pnas_nexus23/index.html">project page</a></li>
							<li><em class="fa fa-file"></em> <a href="https://academic.oup.com/pnasnexus/article/2/5/pgad142/7175271">paper</a></li>
							<li><em class="fa fa-file"></em> <a href="https://www.eurekalert.org/news-releases/989780">press release</a></li>
							<!-- <li><em class="fa fa-file"></em> <a href="https://github.com/Xrvitd/RFEPS">code</a></li> -->
							<!--<li><em class="fa fa-file"></em> <a href="https://www.youtube.com/watch?v=xjTVECIqZfc&feature=youtu.be">video</a></li> -->
							<li>
								<em class="fa fa-bars"></em>
								<a class="toggle_text_link" onclick="javascript:toggle(pnasnexus23);">abstract</a>
								<pre id="pnasnexus23" class="invisible_text">Classrooms are high-risk indoor environments, so analysis of SARS-CoV-2 transmission in classrooms is important for determining optimal interventions. Due to the absence of human behavior data, it is challenging to accurately determine virus exposure in classrooms. A wearable device for close contact behavior detection was developed, and we recorded more than 250-thousand data points of close contact behaviors of students from Grades 1 through 12. Combined with a survey on students’ behaviors, we analyzed virus transmission in classrooms. Close contact rates for students were 37%±11% during classes and 48%±13% during breaks. Students in lower grades had higher close contact rates and virus transmission potential. The long-range airborne transmission route is dominant, accounting for 90%±3.6% and 75%±7.7% with and without mask wearing, respectively. During breaks, the short-range airborne route became more important, contributing 48%±3.1% in grades 1 to 9 (without wearing masks). Ventilation alone cannot always meet the demands of COVID-19 control, 30 m3/h/person is suggested as the threshold outdoor air ventilation rate in classroom. This study provides scientific support for COVID-19 prevention and control in classrooms, and our proposed human behavior detection and analysis methods offer a powerful tool to understand virus transmission characteristics, and can be employed in various indoor environments.</pre>
							</li>
						</ul>
					</div>
				</div>
		<br>
				<div class="row" style="margin-bottom: 1em;">
					<div class="span2 offset2">
						<a href="http://Frank-ZY-Dou.github.io/publication.html">
							<img class="dropshadow pull-right" alt="" src="./figures/22_EST_close.png" width="200" height="120">
						</a>
					</div>
					<div class="span6">
						<a href="">
							<strong>Close Contact Behaviors of University and School Students in 10 Typical Indoor Environments.</strong>
						</a>

						<br> Nan Zhang, Li Liu, <strong>Zhiyang Dou</strong>, Xiyue Liu, Xueze Yang, Doudou Miao, Yong Guo, Silan Gu, Yuguo Li, Hua Qian, Jianjian Wei.<br>
						<em> <b>Journal of Hazardous Materials (JHM) 2023, IF=13.6.</b></em>

						<br>
<!--						<em>System development for close contact behavior collection.</em>-->
<!--						<br>-->
						<ul class="inline middot">
							<li><em class="fa fa-file"></em> <a href="https://www.sciencedirect.com/science/article/pii/S0304389423013523?dgcid=coauthor">paper</a></li>
							<!-- <li><em class="fa fa-file"></em> <a href="https://github.com/Xrvitd/RFEPS">code</a></li> -->
							<!--<li><em class="fa fa-file"></em> <a href="https://www.youtube.com/watch?v=xjTVECIqZfc&feature=youtu.be">video</a></li> -->
							<li>
								<em class="fa fa-bars"></em>
								<a class="toggle_text_link" onclick="javascript:toggle(est);">abstract</a>
								<pre id="est" class="invisible_text">Close contact, including both short-range airborne and large droplet, is recognized as the main route of SARS-CoV-2 transmission in indoor environments, however exposure risk via this route is difficult to quantify due to a lack of data showing close contact behaviors of people in typical indoor environments. A digital wearable device was developed to capture human close contact behaviors automatically based on semi-supervised learning. We collected a total of 337,056 seconds of indoor close contacts from 194 and a half hours of depth video recordings in 10 typical indoor environments. The relationship between SARS-CoV-2 exposure and close contact behaviors were evaluated based on dispersion characteristics of virus-laden droplets. People in restaurant had the highest close contact ratio (63.8%) and probability of face-to-face pattern (77.6%) during close contacts, while people in shopping center had the highest speak fraction (46.6%). University students had higher exposure potential in dormitories than school students in homes, but less exposure potential in classrooms and graduate student offices than school students in classrooms. Aerosol exposure in volume for both short-range inhalation and direct deposition on facial mucosa were highest in restaurants. Classroom is the main indoor environment for SARS-CoV-2 transmission for school students. The obtained results based on real human close contact behaviors can be used for infection risk assessment and to deploy effective interventions against close contact transmission of COVID-19 and other respiratory infections.</pre> <!-- put </pre> on this line to avoid new unwanted line breaks after bibtex -->
							</li>
						</ul>
					</div>
				</div>

<!--					<div class="row" style="margin-bottom: 1em;">-->
<!--					<div class="span2 offset2">-->
<!--						<a href="http://Frank-ZY-Dou.github.io/publication.html">-->
<!--							<img class="dropshadow pull-right" alt="" src="./figures/21_IADR_oc.png" width="200" height="120">-->
<!--						</a>-->
<!--					</div>-->
<!--					<div class="span6">-->
<!--						<a href="">-->
<!--							<strong>Deep Learning to Automate Survival Prediction for Oral Cancer</strong>-->
<!--						</a>-->
<!--						<br>Chui-Shan Chu, <strong>Zhi-Yang Dou</strong>, Joshua-Wk Ho, Li-Wu, Zheng.<br>-->
<!--						<em> <b>International Association for Dental Research (IADR) 2021.</b></em>-->
<!--						<br>-->
<!--						<br>-->
<!--						<ul class="inline middot">-->
<!--							<li><em class="fa fa-file"></em> <a href="">paper</a></li>-->
<!--							&lt;!&ndash; <li><em class="fa fa-file"></em> <a href="">code (coming soon)</a></li> &ndash;&gt;-->
<!--							&lt;!&ndash; <li><em class="fa fa-file"></em> <a href="https://diglib.eg.org/bitstream/handle/10.1111/cgf14484/paper1026_1.pdf?sequence=2&isAllowed=y">suppl.</a></li> &ndash;&gt;-->
<!--							&lt;!&ndash;<li><em class="fa fa-file"></em> <a href="https://www.youtube.com/watch?v=xjTVECIqZfc&feature=youtu.be">video</a></li> &ndash;&gt;-->
<!--							<li>-->
<!--								<em class="fa fa-bars"></em>-->
<!--								<a class="toggle_text_link" onclick="javascript:toggle(oral_cancer);">abstract</a>-->
<!--								<pre id="oral_cancer" class="invisible_text">Objectives: Deep learning is a state-of-the-art tool to analyze prognostic outcomes of cancer patients. However, the use of such analytic method for outcome prediction of oral cancer remains unexplored when compared with other types of cancers like lung and liver cancer. The present study aims to use deep learning to predict one-year survival outcomes of oral squamous cell carcinoma using open-sourced histology images.-->
<!--Methods: This retrospective study used head and neck histology images retrieved from Clinical Proteomic Tumor Analysis Consortium. The dataset included a total of 391 scans with 188 scans of “alive within 12 months” and 24 scans of “death within 12 months”. Annotation on whole slide images was performed and verified by a pathologist in terms of cell types, colors of hematoxylin-and-eosin stain, and image quality. After annotation, 122 scans were qualified for subsequent image tiles generation, then followed by the process of normalization and augmentation. Quantitative evaluation on the performance of the deep learning model was analyzed using the area under the curve.-->
<!--Results: The curated dataset contained more than 30,000 image tiles from 122 scans of tumor, dysplasia, and non-tumor tissue. With a fair split ratio (80:20) for training and test dataset, our deep learning model is expected to achieve more than 50% accuracy.-->
<!--Conclusions: In summary, using curated image data in a sufficient quantity can be used to develop deep learning model for predicting survival outcomes, but may showing suboptimal performance. Future work for enhancing the model performance will be using other machine learning methods to extract additional features.</pre> &lt;!&ndash; put </pre> on this line to avoid new unwanted line breaks after bibtex &ndash;&gt;-->
<!--							</li>-->
<!--						</ul>-->
<!--					</div>-->
<!--				</div>-->

			<br>
			<div class="row" style="margin-bottom: 1em;">
					<div class="span2 offset2">
						<a href="http://Frank-ZY-Dou.github.io/publication.html">
							<img class="dropshadow pull-right" alt="" src="./figures/22_JHM_metro.png" width="200" height="120">
						</a>
					</div>
					<div class="span6">
						<a href="">
							<strong>Close Contact Behavior-based COVID-19 Transmission and Interventions in a Subway System</strong>
						</a>
						<br>Xiyue Liu*, <strong>Zhiyang Dou</strong>*, Lei Wang, Boni Su, Tianyi Jin, Yong Guo, Jianjian Wei, Nan Zhang.<br>
						<em> <b>Journal of Hazardous Materials (JHM) 2022, IF=13.6.</b></em>
						<br>
<!--						<em>Vision system development for human behavior collection and analysis.</em>-->
<!--						<br>-->
						<ul class="inline middot">
							<li><em class="fa fa-file"></em> <a href="https://frank-zy-dou.github.io/projects/Metro_JHM22/index.html">project page</a></li>
							<li><em class="fa fa-file"></em> <a href="https://www.sciencedirect.com/science/article/pii/S0304389422010238">paper</a></li>
							<!-- <li><em class="fa fa-file"></em> <a href="">code (coming soon)</a></li> -->
							<!-- <li><em class="fa fa-file"></em> <a href="https://diglib.eg.org/bitstream/handle/10.1111/cgf14484/paper1026_1.pdf?sequence=2&isAllowed=y">suppl.</a></li> -->
							<!--<li><em class="fa fa-file"></em> <a href="https://www.youtube.com/watch?v=xjTVECIqZfc&feature=youtu.be">video</a></li> -->
							<li>
								<em class="fa fa-bars"></em>
								<a class="toggle_text_link" onclick="javascript:toggle(jhm_metro);">abstract</a>
								<pre id="jhm_metro" class="invisible_text">During COVID-19 pandemic, analysis on virus exposure and intervention efficiency in public transports based on real passenger’s close contact behaviors is critical to curb infectious disease transmission. A monitoring device was developed to gather a total of 145,821 close contact data in subways based on semi-supervision learning. A virus transmission model considering both short- and long-range inhalation and deposition was established to calculate the virus exposure. During rush-hour, short-range inhalation exposure is 3.2 times higher than deposition exposure and 7.5 times higher than long-range inhalation exposure of all passengers in the subway. The close contact rate was 56.1 % and the average interpersonal distance was 0.8 m. Face-to-back was the main pattern during close contact. Comparing with random distribution, if all passengers stand facing in the same direction, personal virus exposure through inhalation (deposition) can be reduced by 74.1 % (98.5 %). If the talk rate was decreased from 20 % to 5 %, the inhalation (deposition) exposure can be reduced by 69.3 % (73.8 %). In addition, we found that virus exposure could be reduced by 82.0 % if all passengers wear surgical masks. This study provides scientific support for COVID-19 prevention and control in subways based on real human close contact behaviors.</pre> <!-- put </pre> on this line to avoid new unwanted line breaks after bibtex -->
							</li>
						</ul>
					</div>
				</div>
				<br>

				<div class="row" style="margin-bottom: 1em;">
					<div class="span2 offset2">
						<a href="http://Frank-ZY-Dou.github.io/publication.html">
							<img class="dropshadow pull-right" alt="" src="./figures/20_TVCG_shape_abs.png" width="200" height="120">
<!--							<img class="dropshadow pull-right" alt="" src="./figures/20_TVCG_Topdown.png" width="200" height="120">-->
						</a>
					</div>
					<div class="span6">
						<a href="">
							<strong>Top-Down Shape Abstraction Based on Greedy Pole Selection</strong>
						</a>
						<br><strong>Zhiyang Dou</strong>, Shiqing Xin, Rui Xu, Jian Xu, Yuanfeng Zhou, Shuangmin Chen, Wenping Wang, Xiuyang Zhao, Changhe Tu.<br>
						<em> <b>IEEE Transactions on Visualization and Computer Graphics. TVCG 2020.</b></em>
						<br>
						<!-- <em>In this paper, I developed vision system for human behavior collection and analysis.</em> -->
						<br>
						<ul class="inline middot">
							<li><em class="fa fa-file"></em> <a href="https://ieeexplore.ieee.org/document/9095378">paper</a></li>
							<!-- <li><em class="fa fa-file"></em> <a href="">code (coming soon)</a></li> -->
							<!-- <li><em class="fa fa-file"></em> <a href="https://diglib.eg.org/bitstream/handle/10.1111/cgf14484/paper1026_1.pdf?sequence=2&isAllowed=y">suppl.</a></li> -->
							<!--<li><em class="fa fa-file"></em> <a href="https://www.youtube.com/watch?v=xjTVECIqZfc&feature=youtu.be">video</a></li> -->
							<li>
								<em class="fa fa-bars"></em>
								<a class="toggle_text_link" onclick="javascript:toggle(tvcg_topdown);">abstract</a>
								<pre id="tvcg_topdown" class="invisible_text">Motivated by the fact that the medial axis transform is able to encode nearly the complete shape, we propose to use as few medial balls as possible to approximate the original enclosed volume by the boundary surface. We progressively select new medial balls, in a top-down style, to enlarge the region spanned by the existing medial balls. The key spirit of the selection strategy is to encourage large medial balls while imposing given geometric constraints. We further propose a speedup technique based on a provable observation that the intersection of medial balls implies the adjacency of power cells (in the sense of the power crust). We further elaborate the selection rules in combination with two closely related applications. One application is to develop an easy-to-use ball-stick modeling system that helps non-professional users to quickly build a shape with only balls and wires, but any penetration between two medial balls must be suppressed. The other application is to generate porous structures with convex, compact (with a high isoperimetric quotient) and shape-aware pores where two adjacent spherical pores may have penetration as long as the mechanical rigidity can be well preserved.</pre> <!-- put </pre> on this line to avoid new unwanted line breaks after bibtex -->
							</li>
						</ul>
					</div>
				</div>





				<p>&nbsp;</p>
			</div><!-- /#main -->





		</div><!-- /#content -->
    </div><!-- /#wrap -->

	

		<footer id="content-info" class="container" role="contentinfo">
		<table width="100%">
			<tbody><tr>
				<td style="text-align:center">
					<div style="display:inline-block;width:210px;"><script type="text/javascript" src="//rf.revolvermaps.com/0/0/7.js?i=563zgztxfth&amp;m=6&amp;c=007eff&amp;cr1=ffffff&amp;br=8&amp;sx=0" async="async"></script>
				</div>
				<p class="copy"><small>Last updated: Oct, 2023</small></p>
					<p class="copy"><small>© 2023 Zhiyang Dou</small></p>
			 </td>
			</tr>


		</tbody></table>
	</footer>


	<!-- From http://stackoverflow.com/a/11668413/72470 -->
	<script>
	  !function ($) {
		$(function(){
		  window.prettyPrint && prettyPrint()
		})
	  }(window.jQuery)
	</script>



<div id="cntvlive2-is-installed"></div></body></html>