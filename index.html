<!DOCTYPE html>
<html class="js no-flexbox canvas canvastext webgl no-touch geolocation postmessage websqldatabase indexeddb hashchange history draganddrop websockets rgba hsla multiplebgs backgroundsize borderimage borderradius boxshadow textshadow opacity cssanimations csscolumns cssgradients cssreflections csstransforms csstransforms3d csstransitions fontface generatedcontent video audio localstorage sessionstorage webworkers applicationcache svg inlinesvg smil svgclippaths gr_weikaichen_github_io" lang="en"><!--<![endif]--><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
	

	<title>Zhiyang (Frank) Dou</title>

	<meta name="viewport" content="width=device-width, initial-scale=1.0">
	<script src="./files/modernizr-2.5.3.min.js.download"></script>

	<script src="./files/jquery.min.js.download"></script>
	<script>window.jQuery || document.write('<script src="/js/vendor/jquery-1.7.2.min.js"><\/script>')</script>

	<script src="./files/spamspan.min.js.download"></script>
	<script src="./files/prettify.js.download"></script>

	<link rel="stylesheet" href="./files/social_widget.css">
	<link rel="stylesheet" href="./files/glyphicons.css">
	<link rel="stylesheet" href="./files/bootstrap.css">
	<link rel="stylesheet" href="./files/bootstrap-responsive.css">
	<link rel="stylesheet" href="./files/app.css">
	<!-- <link rel="stylesheet" href="./files/font-awesome.min.css"> -->
	<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
	<script type="text/javascript" src="./files/plugins.js.download"></script>
	<script type="text/javascript" src="./files/main.js.download"></script>
	<link rel="canonical" href="https://frank-zy-d.github.io/">

	<!-- to toggle text -->
	<style type="text/css">
		a.toggle_text_link {
			cursor:pointer;
		}

		pre.invisible_text {
			display: none;
		}
	</style>
	<script language="javascript" type="text/javascript">
		function toggle(element) {
			if(element.style.display=="block") {
				element.style.display="none";
			} else {
				element.style.display="block";
			}
		}
	</script>
</head>

<body class="home page page-id-4 page-template-default top-navbar" data-gr-c-s-loaded="true">
  <!--[if lt IE 7]><div class="alert">Your browser is <em>ancient!</em> <a href="http://browsehappy.com/">Upgrade to a different browser</a> or <a href="http://www.google.com/chromeframe/?redirect=true">install Google Chrome Frame</a> to experience this site.</div><![endif]-->

    <header id="banner" class="navbar navbar-fixed-top" role="banner">
		<div class="navbar-inner">
			<div class="container">
				<a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
					<!---<span class="icon-bar"></span>
					<span class="icon-bar"></span>
					<span class="icon-bar"></span>
				-->
				</a>
				<a class="brand" href="https://frank-zy-d.github.io/">
					Zhiyang (Frank) Dou
				</a>
				<nav id="nav-main" class="nav-collapse" role="navigation">
					<ul class="nav">
						<li class="menu-home active active"><a href="https://frank-zy-d.github.io/">Home</a></li>
						<li class="menu-publications"><a href="./publication.html">Publications</a></li>
						<!---<li class="menu-cv"><a href="http://herohuyongtao.github.io/cv/">CV</a></li>-->
					</ul>
				</nav>
			</div>
		</div>
	</header>

	<div id="wrap" class="container" role="document">
	<div id="content" class="row">
			<div id="main" class="span8" role="main">
				<div class="page-header">
					<h1>Zhiyang (Frank) Dou</h1>
<!--						<img class="size-medium wp-image-712" style="margin-bottom: 5px;" src="./files/my_name.png" alt="Homepage" width="100" />-->
<!--					</h1>-->
				</div>
				<p>
					<img class=" wp-image-697 alignleft dropshadow" style="margin: 0 1.5em 1em 0; border: 1px solid #222;" src="./files/Frank_avatar4.png" alt="Portrait photo of Frank" width="180" height="200">

					I am a third-year Ph.D. student in CG and CV Group at HKU, supervised by <a href="https://www.cs.hku.hk/people/academic-staff/wenping">Prof. Wenping Wang</a> and <a href="https://www.cs.hku.hk/index.php/people/academic-staff/taku">Prof. Taku Komura</a>. I received my B. Eng. degree with honors at Shandong University.	My undergraduate research advisor is <a href="http://irc.cs.sdu.edu.cn/~shiqing/index.html">Prof. Shiqing Xin</a>.
					
					<br>
					<br>
					Research interests: Character Animation, Geometry Processing, Computer Graphics.


					<!-- I am now a Lead Research Scientist at Tencent America. Previously, I was a postdoc and then a researcher at <a href="http://gl.ict.usc.edu/">Vision and Graphics Lab (VGL)@USC ICT</a> working with <a href="http://www.hao-li.com/Hao_Li/Hao_Li_-_about_me.html"> Prof. Hao Li</a>. I got my PhD from the Department of Computer Science, University of Hong Kong, under <a href="http://i.cs.hku.hk/~wenping/">Prof. Wenping Wang</a>.  -->
					<!---During my Ph.D., I also had a wonderful time visiting <a href="http://www.antexel.com/sylefeb/research"> Dr. Sylvain Lefebvre</a> at <a href="https://www.inria.fr/en/centre/nancy"> Inria, Nancy</a>.
					--> 

					<!-- <br> -->
					<!-- <br> -->
					<!-- My research lies in the interplay among computer graphics, computer vision and machine learning. In particular, I am interested in broad topics in image-based 3D reasoning and 3D deep learning, including 3D reconstruction of humans (face/hair/body), general objects and scenes, differentiable rendering and point cloud analysis.	 -->

					<!-- <br> -->
					<!-- <br> -->

					<!-- My research work <strong><a href="https://github.com/ShichenLiu/SoftRas">SoftRas</strong></a> has been adopted by <strong><a href="https://pytorch3d.org/">Pytorch3D</strong></a> as the basis algorithm for its core function -- differentiable rendering. Check <strong><a href="https://pytorch3d.org/docs/renderer">this</strong></a> out! 				 -->

					<br>
					
				
				<div class="alignbottom visible-desktop">
					<p>
						<a href="https://www.en.sdu.edu.cn/">
							<img class="size-medium wp-image-712" style="margin-bottom: 0px;" src="./files/sdu.png" alt="Shandong University" width="50" />
						</a>
								
						<a href="http://www.hku.hk/">
							<img class="size-medium wp-image-712" style="margin-bottom: 0px;" src="./files/hku2.png" alt="The University of Hong Kong" width="170" />
						</a>
				
				<!-- 		<a href="https://www.inria.fr/en/">
							<img class="size-medium wp-image-712" style="margin-bottom: 0px;" src="./files/inria.png" alt="Inria" width="110" />
						</a>

						<a href="http://ict.usc.edu/">
							<img class="size-medium wp-image-712" style="margin-bottom: 0px;" src="./files/uscict.jpg" alt="USC ICT" width="130" />
						</a>
						<a href="https://www.tencent.com/en-us/index.html">
							<img class="size-medium wp-image-712" style="margin-bottom: 0px;" src="./files/tencent.png" alt="TecentUS" width="90" />
						</a>
				 -->
					</p>
				</div>
				<!---
				</p>
				<p>
					</p><h3><i>Research Interests</i></h3>
					<table border="0" cellpadding="0" style="border:0pt;margin-left:8%">
						<tbody>
							<tr>
								<td style="border:0pt">
									<p align="center" style="text-align:center">
										<b>&nbsp;&nbsp;&nbsp;&nbsp;Computer Vision</b>
									</p>
								</td>
								<td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
								<td style="border:0pt">
									<p align="center" style="text-align:center">
										<b>&nbsp;&nbsp;&nbsp;&nbsp;Computer Graphics</b>
									</p>
								</td>
							</tr>
							<tr>
								<td style="border:0pt">
									<ul>
										<li style="text-align:left">Human Digitization</li>
										<li style="text-align:left">Image-based Reconstruction</li>
										<li style="text-align:left">Deep Learning</li>
									</ul>
								</td>
								<td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</td>
								<td style="border:0pt">
									<ul>
										<li style="text-align:left">Texture/Pattern Synthesis</li>
										<li style="text-align:left">Geometric Modeling</li>
										<li style="text-align:left">Computational Fabrication</li>
									</ul>
								</td>
							</tr>
						</tbody>
					</table>
				<p></p>
				-->
				<!--- News -->
				<hr style="clear: both;">
				<h2>News</h2>
				<dl>
				<ul>
					<li>
						<p>
							<strong>08/2022</strong>: One paper accepted to SIGGRAPH Asia 2022.</a>
						</p>
					</li>


					<li>
						<p>
							<strong>04/2022</strong>: Started Internship at Tencent AI Lab.</a>
						</p>
					</li>

					
					<li>
						<p>
							<strong>02/2022</strong>: One paper accepted to EUROGRAPHICS 2022.</a>
						</p>
					</li>


				<!-- 	<li>
						<p>
							<strong>01/2022</strong>: Received the <strong>"Outstanding Contributor"</strong> award (the best performance rating, top 5%) from Tencent.</strong></a>
						</p>
					</li>
 -->
					<!-- 
					<li>
						<p>
							<strong>11/2019</strong>: Gave an invited talk at <a href="https://games-cn.org/">GAMES</a> web seminar. Slides can be found <a href="https://slides.games-cn.org/pdf/Games2019121%E9%99%88%E4%BC%9F%E5%87%AF.pdf">here.</a>
						</p>
					</li>	
					<li>
						<p>
							<strong>10/2019</strong>: Our work <font color="#FF0000"><strong><a href="https://github.com/ShichenLiu/SoftRas">SoftRas</a> is officially incorporated into <a href="https://pytorch3d.org/">Pytorch3D</a></strong></font> as the basis of differentiable rendering! Check <a href="https://pytorch3d.org/docs/renderer">this</a> out!</a>
						</p>
					</li>
					<li>
						<p>
							<strong>09/2019</strong>: One paper accepted to NeurIPS 2019.</a>
						</p>
					</li>				
					<li>
						<p>
							<strong>08/2019</strong>: I am invited to serve as the Program Committee of AAAI 2020, CVM 2020 and IEEE AIVR 2019.</a>
						</p>
					</li>
					<li>
						<p>
							<strong>07/2019</strong>: Our ICCV'19 paper <a href="https://arxiv.org/pdf/1904.01786.pdf">SoftRas</a> received <strong>three Strong Accepts.</strong></a>
						</p>
					</li>
					<li>
						<p>
							<strong>07/2019</strong>: Three papers accepted to ICCV 2019! Two of them are selected as <strong>Oral Presentation</strong>.</a>
						</p>
					</li> -->
					<!---
					<li>
						<p>
							<strong>06/2019</strong>: One paper accepted to UIST 2019.</a>
						</p>
					</li>
					<li>
						<p>
							<strong>06/2019</strong>: Our oral paper <a href="https://arxiv.org/abs/1901.00049">SiCloPe</a> is selected as <font color="#FF0000"><strong>CVPR Best Paper Finalists</strong></font>.</a>
						</p>
					</li>
					<li>
						<p>
							<strong>03/2019</strong>: I am invited to serve as the Program Committee of SMI-FASE 2019.</a>
						</p>
					</li>
					<li>
						<p>
							<strong>03/2019</strong>: Our CVPR'19 paper  <a href="https://arxiv.org/abs/1901.00049">SiCloPe</a> is selected as <b>Oral Presentation</b>.</a>
						</p>
					</li>
					<li>
						<p>
							<strong>02/2019</strong>: One paper accepted to IEEE VR 2019.</a>
						</p>
					</li>
					<li>
						<p>
							<strong>02/2019</strong>: One paper accepted to CVPR 2019.</a>
						</p>
					</li>
					<li>
						<p>
							<strong>08/2018</strong>: I am invited to serve as the International Program Committee of CVM 2019.</a>
						</p>
					</li>
					<li>
						<p>
							<strong>07/2018</strong>: Two papers accepted to ECCV 2018.</a>
						</p>
					</li>
					<li>
						<p>
							<strong>07/2018</strong>: One paper accepted to BMVC 2018.
						</p>
					</li>
					<li>
						<p>
							<strong>04/2018</strong>: I am invited to serve as the International Program Committee of Pacific Graphics 2018.</a>
						</p>
					</li>
					<li>
						<p>
							<strong>04/2018</strong>: One paper accepted to SIGGRAPH 2018.
						</p>
					</li>
					<li>
						<p>
							<strong>03/2018</strong>: One paper accepted to CVPR 2018 (Spotlight Presentation). </a>
						</p>
					</li>
					<li>
						<p>
							<strong>07/2017</strong>: Two papers accepted to SIGGRAPH Asia 2017. </a>
						</p>
					</li>
					-->
				</ul>
				</dl>
				<!--- Selected Publications -->
				<hr style="clear: both;">
				<!-- <h2>Selected Publications (<a href="https://frank-zy-d.github.io/publication.html">Full List</a>)</h2> -->
				<h2>Selected Publications</h2>
				 * Equal contribution.
				<dl>

				<div class="row">
					<div class="span2" style="margin-bottom: 2em;">
						<a href="https://frank-zy-d.github.io/publication.html">
							<img class="dropshadow pull-right" alt="" src="./figures/22_SIGA_rfeps.png" width="200" height="120">
						</a>
					</div>
					<div class="span6">
						<a href="">
							<strong>RFEPS: Reconstructing Feature-line Equipped Polygonal Surface</strong>
						</a>
						<br>Rui Xu, Zixiong Wang, <strong>Zhiyang Dou</strong>, Chen Zong, Shiqing Xin, Mingyan Jiang, Tao Ju, Changhe Tu.<br>
						<em> <b>ACM Transactions on Graphics. SIGGRAPH Asia 2022.</b></em>
						<br>
						<!-- <em>"a learnable implicit representation for modeling both closed and open surfaces"</em> -->
						<br>
						<ul class="inline middot">
							<li><em class="fa fa-file"></em> <a href="https://arxiv.org/abs/2212.03600">paper</a></li>
							<li><em class="fa fa-file"></em> <a href="https://github.com/Xrvitd/RFEPS">code</a></li>
							<!-- <li><em class="fa fa-file"></em> <a href="./papers/[ECCV18]body supplementary.pdf">suppl.</a></li> -->
							<!--<li><em class="fa fa-file"></em> <a href="https://www.youtube.com/watch?v=xjTVECIqZfc&feature=youtu.be">video</a></li> -->
							<li>
								<em class="fa fa-bars"></em>
								<a class="toggle_text_link" onclick="javascript:toggle(rfeps);">abstract</a>
								<pre id="rfeps" class="invisible_text">Feature lines are important geometric cues in characterizing the structure of a CAD model. Despite great progress in both explicit reconstruction and implicit reconstruction, it remains a challenging task to reconstruct a polygonal surface equipped with feature lines, especially when the input point cloud is noisy and lacks faithful normal vectors. In this paper, we develop a multistage algorithm, named RFEPS, to address this challenge. The key steps include (1)denoising the point cloud based on the assumption of local planarity, (2)identifying the feature-line zone by optimization of discrete optimal transport, (3)augmenting the point set so that sufficiently many additional points are generated on potential geometry edges, and (4) generating a polygonal surface that interpolates the augmented point set based on restricted power diagram. We demonstrate through extensive experiments that RFEPS, benefiting from the edge-point augmentation and the feature-preserving explicit reconstruction, outperforms state-of-the-art methods in terms of the reconstruction quality, especially in terms of the ability to reconstruct missing feature lines.</pre> <!-- put </pre> on this line to avoid new unwanted line breaks after bibtex -->
							</li>
							
						</ul>
					</div>
				</div>

				<div class="row">
					<div class="span2" style="margin-bottom: 2em;">
						<a href="https://frank-zy-d.github.io/publication.html">
							<img class="dropshadow pull-right" alt="" src="./figures/22_arxiv_TORE.png" width="200" height="120">
						</a>
					</div>
					<div class="span6">
						<a href="">
							<strong>TORE: Token Reduction for Efficient Human Mesh Recovery with Transformer</strong>
						</a>
						<br><strong>Zhiyang Dou</strong>*, Qingxuan Wu*, Cheng Lin, Zeyu Cao, Qiangqiang Wu, Weilin Wan, Taku Komura, Wenping Wang.<br>
						<em> <b>Arxiv 2023.</b></em>
						<br>
						<!-- <em>"a learnable implicit representation for modeling both closed and open surfaces"</em> -->
						<br>
						<ul class="inline middot">
							<li><em class="fa fa-file"></em> <a href="https://arxiv.org/abs/2211.10705">paper</a></li>
							<li><em class="fa fa-file"></em> <a href="">code (coming soon)</a></li>
							<!-- <li><em class="fa fa-file"></em> <a href="https://diglib.eg.org/bitstream/handle/10.1111/cgf14484/paper1026_1.pdf?sequence=2&isAllowed=y">suppl.</a></li> -->
							<!--<li><em class="fa fa-file"></em> <a href="https://www.youtube.com/watch?v=xjTVECIqZfc&feature=youtu.be">video</a></li> -->
							<li>
								<em class="fa fa-bars"></em>
								<a class="toggle_text_link" onclick="javascript:toggle(tore);">abstract</a>
								<pre id="tore" class="invisible_text">In this paper, we introduce a set of effective TOken REduction (TORE) strategies for Transformer-based Human Mesh Recovery from monocular images. Current SOTA performance is achieved by Transformer-based structures. However, they suffer from high model complexity and computation cost caused by redundant tokens. We propose token reduction strategies based on two important aspects, i.e., the 3D geometry structure and 2D image feature, where we hierarchically recover the mesh geometry with priors from body structure and conduct token clustering to pass fewer but more discriminative image feature tokens to the Transformer. As a result, our method vastly reduces the number of tokens involved in high-complexity interactions in the Transformer, achieving competitive accuracy of shape recovery at a significantly reduced computational cost. We conduct extensive experiments across a wide range of benchmarks to validate the proposed method and further demonstrate the generalizability of our method on hand mesh recovery. Our code will be publicly available once the paper is published.
</pre> <!-- put </pre> on this line to avoid new unwanted line breaks after bibtex -->
							</li>
						</ul>
					</div>
				</div>




				<div class="row">
					<div class="span2" style="margin-bottom: 2em;">
						<a href="https://frank-zy-d.github.io/publication.html">
							<img class="dropshadow pull-right" alt="" src="./figures/22_EG_CAT.png" width="200" height="120">
						</a>
					</div>
					<div class="span6">
						<a href="">
							<strong>Coverage Axis: Inner Point Selection for 3D Shape Skeletonization</strong>
						</a>
						<br><strong>Zhiyang Dou</strong>, Cheng Lin, Rui Xu, Lei Yang, Shiqing Xin, Taku Komura, Wenping Wang.<br>
						<em> <b>Computer Graphics Forum. Eurographics 2022.</b></em>
						<br>
						<!-- <em>"a learnable implicit representation for modeling both closed and open surfaces"</em> -->
						<br>
						<ul class="inline middot">
							<li><em class="fa fa-file"></em> <a href="https://arxiv.org/abs/2110.00965">paper</a></li>
							<!-- <li><em class="fa fa-file"></em> <a href="https://github.com/Xrvitd/RFEPS">code</a></li> -->
							<li><em class="fa fa-file"></em> <a href="https://diglib.eg.org/bitstream/handle/10.1111/cgf14484/paper1026_1.pdf?sequence=2&isAllowed=y">suppl.</a></li>
							<!--<li><em class="fa fa-file"></em> <a href="https://www.youtube.com/watch?v=xjTVECIqZfc&feature=youtu.be">video</a></li> -->
							<li>
								<em class="fa fa-bars"></em>
								<a class="toggle_text_link" onclick="javascript:toggle(cat);">abstract</a>
								<pre id="cat" class="invisible_text">In this paper, we present a simple yet effective formulation called Coverage Axis for 3D shape skeletonization. Inspired by the set cover problem, our key idea is to cover all the surface points using as few inside medial balls as possible. This formulation inherently induces a compact and expressive approximation of the Medial Axis Transform (MAT) of a given shape. Different from previous methods that rely on local approximation error, our method allows a global consideration of the overall shape structure, leading to an efficient high-level abstraction and superior robustness to noise. Another appealing aspect of our method is its capability to handle more generalized input such as point clouds and poor-quality meshes. Extensive comparisons and evaluations demonstrate the remarkable effectiveness of our method for generating compact and expressive skeletal representation to approximate the MAT.</pre> <!-- put </pre> on this line to avoid new unwanted line breaks after bibtex -->
							</li>
						</ul>
					</div>
				</div>

				<div class="row">
					<div class="span2" style="margin-bottom: 2em;">
						<a href="https://frank-zy-d.github.io/publication.html">
							<img class="dropshadow pull-right" alt="" src="./figures/22_JHM_metro.png" width="200" height="120">
						</a>
					</div>
					<div class="span6">
						<a href="">
							<strong>Close Contact Behavior-based COVID-19 Transmission and Interventions in a Subway System</strong>
						</a>
						<br>Xiyue Liu*, <strong>Zhiyang Dou</strong>*, Lei Wang, Boni Su, Tianyi Jin, Yong Guo, Jianjian Wei, Nan Zhang.<br>
						<em> <b>Journal of Hazardous Materials 2022, IF=14.2.</b></em>
						<br>
						<em>In this paper, I developed vision system for human behavior collection and analysis.</em>
						<br>
						<ul class="inline middot">
							<li><em class="fa fa-file"></em> <a href="https://www.sciencedirect.com/science/article/pii/S0304389422010238">paper</a></li>
							<!-- <li><em class="fa fa-file"></em> <a href="">code (coming soon)</a></li> -->
							<!-- <li><em class="fa fa-file"></em> <a href="https://diglib.eg.org/bitstream/handle/10.1111/cgf14484/paper1026_1.pdf?sequence=2&isAllowed=y">suppl.</a></li> -->
							<!--<li><em class="fa fa-file"></em> <a href="https://www.youtube.com/watch?v=xjTVECIqZfc&feature=youtu.be">video</a></li> -->
							<li>
								<em class="fa fa-bars"></em>
								<a class="toggle_text_link" onclick="javascript:toggle(jhm_metro);">abstract</a>
								<pre id="jhm_metro" class="invisible_text">During COVID-19 pandemic, analysis on virus exposure and intervention efficiency in public transports based on real passenger’s close contact behaviors is critical to curb infectious disease transmission. A monitoring device was developed to gather a total of 145,821 close contact data in subways based on semi-supervision learning. A virus transmission model considering both short- and long-range inhalation and deposition was established to calculate the virus exposure. During rush-hour, short-range inhalation exposure is 3.2 times higher than deposition exposure and 7.5 times higher than long-range inhalation exposure of all passengers in the subway. The close contact rate was 56.1 % and the average interpersonal distance was 0.8 m. Face-to-back was the main pattern during close contact. Comparing with random distribution, if all passengers stand facing in the same direction, personal virus exposure through inhalation (deposition) can be reduced by 74.1 % (98.5 %). If the talk rate was decreased from 20 % to 5 %, the inhalation (deposition) exposure can be reduced by 69.3 % (73.8 %). In addition, we found that virus exposure could be reduced by 82.0 % if all passengers wear surgical masks. This study provides scientific support for COVID-19 prevention and control in subways based on real human close contact behaviors.</pre> <!-- put </pre> on this line to avoid new unwanted line breaks after bibtex -->
							</li>
						</ul>
					</div>
				</div>



				<div class="row">
					<div class="span2" style="margin-bottom: 2em;">
						<a href="https://frank-zy-d.github.io/publication.html">
							<img class="dropshadow pull-right" alt="" src="./figures/20_TVCG_topdown.png" width="200" height="120">
						</a>
					</div>
					<div class="span6">
						<a href="">
							<strong>Top-Down Shape Abstraction Based on Greedy Pole Selection</strong>
						</a>
						<br><strong>Zhiyang Dou</strong>, Shiqing Xin, Rui Xu, Jian Xu, Yuanfeng Zhou, Shuangmin Chen, Wenping Wang, Xiuyang Zhao, Changhe Tu.<br>
						<em> <b>IEEE Transactions on Visualization and Computer Graphics. TVCG 2020.</b></em>
						<br>
						<!-- <em>In this paper, I developed vision system for human behavior collection and analysis.</em> -->
						<br>
						<ul class="inline middot">
							<li><em class="fa fa-file"></em> <a href="https://ieeexplore.ieee.org/document/9095378">paper</a></li>
							<!-- <li><em class="fa fa-file"></em> <a href="">code (coming soon)</a></li> -->
							<!-- <li><em class="fa fa-file"></em> <a href="https://diglib.eg.org/bitstream/handle/10.1111/cgf14484/paper1026_1.pdf?sequence=2&isAllowed=y">suppl.</a></li> -->
							<!--<li><em class="fa fa-file"></em> <a href="https://www.youtube.com/watch?v=xjTVECIqZfc&feature=youtu.be">video</a></li> -->
							<li>
								<em class="fa fa-bars"></em>
								<a class="toggle_text_link" onclick="javascript:toggle(tvcg_topdown);">abstract</a>
								<pre id="tvcg_topdown" class="invisible_text">Motivated by the fact that the medial axis transform is able to encode nearly the complete shape, we propose to use as few medial balls as possible to approximate the original enclosed volume by the boundary surface. We progressively select new medial balls, in a top-down style, to enlarge the region spanned by the existing medial balls. The key spirit of the selection strategy is to encourage large medial balls while imposing given geometric constraints. We further propose a speedup technique based on a provable observation that the intersection of medial balls implies the adjacency of power cells (in the sense of the power crust). We further elaborate the selection rules in combination with two closely related applications. One application is to develop an easy-to-use ball-stick modeling system that helps non-professional users to quickly build a shape with only balls and wires, but any penetration between two medial balls must be suppressed. The other application is to generate porous structures with convex, compact (with a high isoperimetric quotient) and shape-aware pores where two adjacent spherical pores may have penetration as long as the mechanical rigidity can be well preserved.</pre> <!-- put </pre> on this line to avoid new unwanted line breaks after bibtex -->
							</li>
						</ul>
					</div>
				</div>




				</dl>
			

			</div><!-- /#main -->

			<aside id="sidebar" class="span4" role="complementary">
				<div class="well">
					<section id="text-2" class="widget-1 widget-first widget widget_text">
						<div class="widget-inner">
							<h3>Contact info</h3>
							<div class="textwidget"><h6>Email</h6>
								<a class="email" href="mailto:zhiyang0@connect.hku.hk">zhiyang0@connect.hku.hk</a>
								<h6>Address</h6>
								<i>
									CYC Bldg 416, The University of Hong Kong, Pokfulam Road, Hong Kong.
								</i>
							</div>							
						</div>
					</section>
				
					<br>
					<section id="text-2" class="widget-1 widget-first widget widget_text">
						<div class="widget-inner">
							<h3> <a href="./files/CV_Zhiyang(Frank)_Dou.pdf"> Curriculum Vitae </a></h3>
						</div>
					</section>
					<br>
		
					<section id="social-widget-2" class="widget-3 widget Social_Widget">
						<div class="widget-inner">
							<h3>More Links</h3>
							<div class="socialmedia-buttons smw_left">
								<a href="https://scholar.google.com/citations?user=SLRYlKsAAAAJ&hl=en" rel="publisher" target="_blank">
									<img width="32" height="32" src="./files/scholar.png" alt="Google Scholar" title="Google Scholar" style="opacity: 0.8; -moz-opacity: 0.8;" class="fade">
								</a>
								<a href="https://github.com/Frank-ZY-D" rel="nofollow" target="_blank">
									<img width="32" height="32" src="./files/github.png" alt="GitHub" title="GitHub" style="opacity: 0.8; -moz-opacity: 0.8;" class="fade">
								</a>					
								<a href="https://www.linkedin.com/in/zhiyang-dou-0259111b3/" rel="nofollow" target="_blank">
									<img width="32" height="32" src="./files/linkedin.png" alt="LinkedIn" title="LinkedIn" style="opacity: 0.8; -moz-opacity: 0.8;" class="fade">
								</a>
									<a href="https://twitter.com/Frank95598117/" rel="nofollow" target="_blank">
									<img width="32" height="32" src="./files/twitter.png" alt="twitter" title="twitter" style="opacity: 0.8; -moz-opacity: 0.8;" class="fade">
								</a>



								

							<!-- 	<a href="https://www.facebook.com/chen.weikai.3" rel="nofollow" target="_blank">
									<img width="32" height="32" src="./files/facebook.png" alt="Follow me on Facebook" title="Follow me on Facebook" style="opacity: 0.8; -moz-opacity: 0.8;" class="fade">
								</a> -->
							<script type="text/javascript" src="//rf.revolvermaps.com/0/0/1.js?i=5tt5ry8fn14&amp;s=340&amp;m=6&amp;v=true&amp;r=false&amp;b=000000&amp;n=false&amp;c=ff0000" async="async"></script>
								<!-- site credits -->
								<br><br>
								<em class="fa fa-credit-card"></em> <a class="toggle_text_link" onclick="javascript:toggle(site_credits);">Site Credits</a>
								<pre id="site_credits" class="invisible_text">
This site was built using <a href="http://twitter.github.io/bootstrap/">Bootstrap</a>, a front-end framework for web development. <br /><br />The style of this site is inspired by <a href="http://richardt.name/">Dr. Christian Richardt</a>'s and <a href="http://herohuyongtao.github.io/">Dr. Yongtao Hu</a>'s personal website.</pre> <!-- put </pre> on this line to avoid new unwanted line breaks after bibtex -->
								
							</div>
						</div>
					</section>
				</div>
			</aside><!-- /#sidebar -->
		</div><!-- /#content -->
	</div><!-- /#wrap -->

	<footer id="content-info" class="container" role="contentinfo">
		<table width="100%">
			<tbody><tr>
				<td>
					<p class="copy"><small>© 2023 Zhiyang Dou</small></p>
				</td>
			</tr>
		</tbody></table>
	</footer>

	<!-- From http://stackoverflow.com/a/11668413/72470 
	<script>
	  !function ($) {
		$(function(){
		  window.prettyPrint && prettyPrint()
		})
	  }(window.jQuery)
	</script>
	-->	
	

<div id="cntvlive2-is-installed"></div></body></html>